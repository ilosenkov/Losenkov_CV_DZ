{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5944b01-2816-4dfe-b843-c45f368b30d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "print('CUDA available' if tf.config.list_physical_devices('GPU') else 'CUDA not available')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c57380-b46a-466e-a9a3-ffe5735bdab9",
   "metadata": {},
   "source": [
    "**1. Загрузка данных**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69ccf87a-2952-4085-9940-33cce6f1b35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels.h5\n",
      "225209952/225209952 [==============================] - 21s 0us/step\n"
     ]
    }
   ],
   "source": [
    "#Загрузка модели InceptionResNetV2\n",
    "from tensorflow.keras.applications import InceptionResNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef73a056-3faa-4a3d-98b4-c7cfc08e5271",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from random import shuffle\n",
    "from glob import glob\n",
    "\n",
    "IMG_SIZE = (224, 224)  # размер входного изображения сети\n",
    "\n",
    "train_files = glob(r'D:\\НЕТОЛОГИЯ\\Comp Vision\\файлы\\dogs-vs-cats-redux-kernels-edition\\train/*.jpg')\n",
    "test_files = glob(r'D:\\НЕТОЛОГИЯ\\Comp Vision\\файлы\\dogs-vs-cats-redux-kernels-edition\\test/*.jpg')\n",
    "\n",
    "# загружаем входное изображение и предобрабатываем\n",
    "def load_image(path, target_size=IMG_SIZE):\n",
    "    img = plt.imread(path)[...,::-1]\n",
    "    img = cv2.resize(img, target_size)\n",
    "    return tf.keras.applications.inception_resnet_v2.preprocess_input(img)\n",
    "\n",
    "# функция-генератор загрузки обучающих данных с диска\n",
    "def fit_generator(files, batch_size=32):\n",
    "    batch_size = min(batch_size, len(files))\n",
    "    while True:\n",
    "        shuffle(files)\n",
    "        for k in range(len(files) // batch_size):\n",
    "            i = k * batch_size\n",
    "            j = i + batch_size\n",
    "            if j > len(files):\n",
    "                j = - j % len(files)\n",
    "            x = np.array([load_image(path) for path in files[i:j]])\n",
    "            y = np.array([1. if os.path.basename(path).startswith('dog') else 0.\n",
    "                          for path in files[i:j]])\n",
    "            yield (x, y)\n",
    "# функция-генератор загрузки тестовых изображений с диска\n",
    "def predict_generator(files):\n",
    "    while True:\n",
    "        for path in files:\n",
    "            yield np.array([load_image(path)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45037a29-538d-414a-81f3-650386e5e575",
   "metadata": {},
   "source": [
    "**2. Создание модели**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a22736-c28a-4af4-bb3e-3545b36d100c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iresnet_base = InceptionResNetV2(include_top = False,\n",
    "    weights='imagenet',\n",
    "    input_shape = (IMG_SIZE[0], IMG_SIZE[1], 3),\n",
    "    classes = 2,\n",
    "    classifier_activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3ae3e3e-fe50-4316-88f1-c099eb5cc6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# фиксируем все веса предобученной сети\n",
    "for layer in iresnet_base.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Вместо 7 послдених слоев добавлем один полносвязный слой\n",
    "x = iresnet_base.layers[-9].output\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(1, activation='sigmoid', kernel_regularizer=tf.keras.regularizers.l1(1e-4))(x)\n",
    "\n",
    "model = tf.keras.Model(inputs = iresnet_base.input, outputs = x, name='dogs_vs_cats')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809167b6-a117-4a0a-b86e-d55e59baf7e6",
   "metadata": {},
   "source": [
    "**3. Компиляция и обучение модели**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "847d4ccf-afab-4a64-875c-6adadbb69e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eda041cc-0c84-4763-beb8-888009cfc8f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10/10 [==============================] - 22s 1s/step - loss: 0.7368 - accuracy: 0.6125 - val_loss: 0.2111 - val_accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 7s 720ms/step - loss: 0.3420 - accuracy: 0.8687 - val_loss: 0.1899 - val_accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 7s 728ms/step - loss: 0.2457 - accuracy: 0.9375 - val_loss: 0.1548 - val_accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 7s 756ms/step - loss: 0.2217 - accuracy: 0.9281 - val_loss: 0.0824 - val_accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 7s 744ms/step - loss: 0.1620 - accuracy: 0.9594 - val_loss: 0.0717 - val_accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 7s 720ms/step - loss: 0.1817 - accuracy: 0.9406 - val_loss: 0.0386 - val_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 8s 830ms/step - loss: 0.1679 - accuracy: 0.9469 - val_loss: 0.0788 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 9s 906ms/step - loss: 0.1765 - accuracy: 0.9312 - val_loss: 0.0872 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 8s 778ms/step - loss: 0.1398 - accuracy: 0.9625 - val_loss: 0.0555 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 7s 735ms/step - loss: 0.1133 - accuracy: 0.9656 - val_loss: 0.0844 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 7s 701ms/step - loss: 0.1654 - accuracy: 0.9406 - val_loss: 0.0915 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 7s 734ms/step - loss: 0.1150 - accuracy: 0.9563 - val_loss: 0.0264 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 8s 849ms/step - loss: 0.1485 - accuracy: 0.9531 - val_loss: 0.0688 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 7s 723ms/step - loss: 0.1144 - accuracy: 0.9750 - val_loss: 0.0280 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 7s 684ms/step - loss: 0.1188 - accuracy: 0.9594 - val_loss: 0.0666 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 7s 704ms/step - loss: 0.1550 - accuracy: 0.9406 - val_loss: 0.0622 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 7s 687ms/step - loss: 0.1547 - accuracy: 0.9406 - val_loss: 0.0416 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 7s 697ms/step - loss: 0.1718 - accuracy: 0.9312 - val_loss: 0.0418 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 7s 661ms/step - loss: 0.1238 - accuracy: 0.9594 - val_loss: 0.1418 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 7s 679ms/step - loss: 0.1477 - accuracy: 0.9438 - val_loss: 0.1671 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c6335c72b0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_samples = 5  # число изображений в валидационной выборке\n",
    "\n",
    "shuffle(train_files)  # перемешиваем обучающую выборку\n",
    "validation_data = next(fit_generator(train_files[:val_samples], val_samples))\n",
    "train_data = fit_generator(train_files[val_samples:])  # данные читаем функцией-генератором\n",
    "\n",
    "# запускаем процесс обучения\n",
    "model.fit(train_data,\n",
    "          steps_per_epoch = 10,  # число вызовов генератора за эпоху\n",
    "          epochs = 20,  # число эпох обучения\n",
    "          validation_data=validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "31d8ce83-587c-440d-beee-e0193baf861b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('D:\\НЕТОЛОГИЯ\\Comp Vision\\файлы\\cats-dogs-inresnetv2.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "670cfe5f-df7a-4ad2-a4da-f2f8c9b08402",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('D:\\НЕТОЛОГИЯ\\Comp Vision\\файлы\\cats-dogs-inresnetv2.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d4aac5-5309-4db1-8427-50d0e3682902",
   "metadata": {},
   "source": [
    "**4. Предсказания на тестовой выборке**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c6847bb-7d24-4a62-9983-404ab1646240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 406s 32ms/step\n"
     ]
    }
   ],
   "source": [
    "test_pred = model.predict(predict_generator(test_files), steps=len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "808ca899-dc99-481a-be8c-aa896029a75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "with open(r'D:\\НЕТОЛОГИЯ\\Comp Vision\\файлы\\dc_prediction.csv', 'w') as dst:\n",
    "    dst.write('id,label\\n')\n",
    "    for path, score in zip(test_files, test_pred):\n",
    "        dst.write('%s,%f\\n' % (re.search('(\\d+).jpg$', path).group(1), score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
